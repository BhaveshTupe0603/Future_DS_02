# -*- coding: utf-8 -*-
"""FUTURE_DS_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aEjV34vIMh7db1uXYy18sYLyv0avGyQA

### **ðŸ“Œ Task 2: Customer Support Data Analysis**


---


In this task, we aim to analyze customer support tickets to identify the most frequently reported issues and recommend solutions to improve response and resolution times.  

The goal is to:
- Identify the most common problems faced by customers based on ticket descriptions.  
- Analyze patterns in ticket priority, channels, and customer satisfaction ratings.  
- Extract keywords from closed tickets to uncover trends in customer concerns.  

This type of analysis is crucial for customer service teams, product support engineers, and business decision-makers as it provides insight into customer pain points, highlights inefficiencies in support workflows, and enables data-driven process improvements to enhance customer experience.
"""

# Basic libraries
import pandas as pd
import numpy as np

# For text preprocessing
import nltk
import string

# Download NLTK resources (only once)
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Visualization (optional for later)
import matplotlib.pyplot as plt
import seaborn as sns

# Replace 'support_tickets.csv' with the actual file name
df = pd.read_csv('/content/drive/MyDrive/customer_support_tickets.csv')

# View the first 5 rows
df.head()

# Check column names, data types, and null values
df.info()

df.isnull().sum()

# 2.1 Clean column names
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

# 2.2 Check missing values again
missing_counts = df.isnull().sum()
missing_percentage = (missing_counts / len(df)) * 100

missing_df = pd.DataFrame({
    'Missing Count': missing_counts,
    'Missing %': missing_percentage
}).sort_values(by='Missing %', ascending=False)

missing_df

# 3.1 Filter closed tickets for resolution analysis
closed_df = df[df['ticket_status'].str.lower() == 'closed'].copy()

# Check how many we have
print(f"Closed tickets count: {len(closed_df)}")

# 3.2 Convert datetime columns
closed_df['first_response_time'] = pd.to_datetime(closed_df['first_response_time'], errors='coerce')
closed_df['time_to_resolution'] = pd.to_datetime(closed_df['time_to_resolution'], errors='coerce')

# 3.3 Compute response/resolution durations in minutes
closed_df['response_minutes'] = (closed_df['first_response_time'] - pd.to_datetime(closed_df['date_of_purchase'])).dt.total_seconds() / 60
closed_df['resolution_minutes'] = (closed_df['time_to_resolution'] - pd.to_datetime(closed_df['date_of_purchase'])).dt.total_seconds() / 60

# 3.4 Drop rows where these values are still missing (optional)
closed_df = closed_df.dropna(subset=['response_minutes', 'resolution_minutes'])

# Preview result
closed_df[['ticket_id', 'response_minutes', 'resolution_minutes', 'customer_satisfaction_rating']].head()

import nltk

# Download required NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import re
from collections import Counter
import string

# Initialize tools
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    if pd.isna(text):
        return ""
    text = re.sub(r'{.*?}', '', text)
    text = re.sub(r'\d+', '', text)
    text = text.lower()
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and w not in string.punctuation]
    return tokens

# Apply preprocessing
closed_df['clean_tokens'] = closed_df['ticket_description'].apply(preprocess)

# Flatten tokens and find top 20
all_words = [word for tokens in closed_df['clean_tokens'] for word in tokens]
common_words = Counter(all_words).most_common(20)
common_words

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Combine all keyword groups into a single string
keywords_text = ' '.join(summary_df["Keyword Group"].tolist())

# Generate the WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(keywords_text)

# Display the WordCloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Common Issues in Customer Support Tickets', fontsize=14)
plt.show()

import pandas as pd

# Define the data
summary_data = {
    "Keyword Group": [
        "issue, problem, unable, resolve",
        "please, assist, update",
        "product, device, software",
        "account, data, time",
        "step, noticed"
    ],
    "Frequency": [
        "High",
        "High",
        "High",
        "Moderate",
        "Notable"
    ],
    "Insight": [
        "Customers frequently face functional difficulties.",
        "Many are requesting direct help or reporting outdated systems.",
        "Issues are product/device/software-specific.",
        "Access, privacy, and timing are pain points.",
        "Customers often describe steps taken or anomalies observed."
    ]
}

# Create the DataFrame
summary_df = pd.DataFrame(summary_data)

# Display the table
summary_df

# Export to CSV
summary_df.to_csv("customer_support_summary.csv", index=False)

# Download the file (for Google Colab)
from google.colab import files
files.download("customer_support_summary.csv")

""" **âœ… Conclusion / Insights**


---


The analysis of customer support tickets revealed several important patterns:

- **Recurring Issues**: Keywords such as *issue*, *problem*, *unable*, and *resolve* appeared frequently, indicating a high volume of functional and technical difficulties faced by users.
- **Help Requests**: Words like *please*, *assist*, and *update* suggest that customers are actively seeking support and expect timely resolution.
- **Product-Specific Concerns**: Terms like *product*, *device*, and *software* point to issues that are often tied to specific tools or technologies.
- **Access and Data Problems**: Mentions of *account*, *data*, and *time* highlight common concerns related to login, privacy, and service delays.

Additionally, a significant number of tickets lacked timely first responses and resolution times, pointing to inefficiencies in the current support workflow.  

**Recommendation**:  
To improve customer satisfaction and streamline resolution processes, organizations should consider:
- Automating common responses using chatbots or knowledge bases.
- Prioritizing ticket types based on keyword trends.
- Enhancing support documentation to empower self-service.

By leveraging data-driven insights, support teams can not only reduce resolution time but also build stronger relationships with customers through more effective and empathetic service.

"""