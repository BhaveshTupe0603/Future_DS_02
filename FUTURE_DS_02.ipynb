{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“Œ Task 2: Customer Support Data Analysis**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this task, we aim to analyze customer support tickets to identify the most frequently reported issues and recommend solutions to improve response and resolution times.  \n",
        "\n",
        "The goal is to:\n",
        "- Identify the most common problems faced by customers based on ticket descriptions.  \n",
        "- Analyze patterns in ticket priority, channels, and customer satisfaction ratings.  \n",
        "- Extract keywords from closed tickets to uncover trends in customer concerns.  \n",
        "\n",
        "This type of analysis is crucial for customer service teams, product support engineers, and business decision-makers as it provides insight into customer pain points, highlights inefficiencies in support workflows, and enables data-driven process improvements to enhance customer experience.\n"
      ],
      "metadata": {
        "id": "rIDs2rupBgCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For text preprocessing\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (only once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Visualization (optional for later)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "F0Es8U1M-Saz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'support_tickets.csv' with the actual file name\n",
        "df = pd.read_csv('/content/drive/MyDrive/customer_support_tickets.csv')\n"
      ],
      "metadata": {
        "id": "AruMJSeE-TrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 5 rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "fC0XQAMn-zZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names, data types, and null values\n",
        "df.info()"
      ],
      "metadata": {
        "id": "mdDmx2kp-1wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Pct6kbs5Abml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 Clean column names\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# 2.2 Check missing values again\n",
        "missing_counts = df.isnull().sum()\n",
        "missing_percentage = (missing_counts / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_counts,\n",
        "    'Missing %': missing_percentage\n",
        "}).sort_values(by='Missing %', ascending=False)\n",
        "\n",
        "missing_df\n"
      ],
      "metadata": {
        "id": "2gBcrqgI_D5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Filter closed tickets for resolution analysis\n",
        "closed_df = df[df['ticket_status'].str.lower() == 'closed'].copy()\n",
        "\n",
        "# Check how many we have\n",
        "print(f\"Closed tickets count: {len(closed_df)}\")\n",
        "\n",
        "# 3.2 Convert datetime columns\n",
        "closed_df['first_response_time'] = pd.to_datetime(closed_df['first_response_time'], errors='coerce')\n",
        "closed_df['time_to_resolution'] = pd.to_datetime(closed_df['time_to_resolution'], errors='coerce')\n",
        "\n",
        "# 3.3 Compute response/resolution durations in minutes\n",
        "closed_df['response_minutes'] = (closed_df['first_response_time'] - pd.to_datetime(closed_df['date_of_purchase'])).dt.total_seconds() / 60\n",
        "closed_df['resolution_minutes'] = (closed_df['time_to_resolution'] - pd.to_datetime(closed_df['date_of_purchase'])).dt.total_seconds() / 60\n",
        "\n",
        "# 3.4 Drop rows where these values are still missing (optional)\n",
        "closed_df = closed_df.dropna(subset=['response_minutes', 'resolution_minutes'])\n",
        "\n",
        "# Preview result\n",
        "closed_df[['ticket_id', 'response_minutes', 'resolution_minutes', 'customer_satisfaction_rating']].head()\n"
      ],
      "metadata": {
        "id": "mB2q3fn8_PMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "JtOs4OVq_il9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Initialize tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r'{.*?}', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and w not in string.punctuation]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "closed_df['clean_tokens'] = closed_df['ticket_description'].apply(preprocess)\n",
        "\n",
        "# Flatten tokens and find top 20\n",
        "all_words = [word for tokens in closed_df['clean_tokens'] for word in tokens]\n",
        "common_words = Counter(all_words).most_common(20)\n",
        "common_words\n"
      ],
      "metadata": {
        "id": "E3npsoif_REb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Combine all keyword groups into a single string\n",
        "keywords_text = ' '.join(summary_df[\"Keyword Group\"].tolist())\n",
        "\n",
        "# Generate the WordCloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(keywords_text)\n",
        "\n",
        "# Display the WordCloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Common Issues in Customer Support Tickets', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B1RSZPrRAGU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the data\n",
        "summary_data = {\n",
        "    \"Keyword Group\": [\n",
        "        \"issue, problem, unable, resolve\",\n",
        "        \"please, assist, update\",\n",
        "        \"product, device, software\",\n",
        "        \"account, data, time\",\n",
        "        \"step, noticed\"\n",
        "    ],\n",
        "    \"Frequency\": [\n",
        "        \"High\",\n",
        "        \"High\",\n",
        "        \"High\",\n",
        "        \"Moderate\",\n",
        "        \"Notable\"\n",
        "    ],\n",
        "    \"Insight\": [\n",
        "        \"Customers frequently face functional difficulties.\",\n",
        "        \"Many are requesting direct help or reporting outdated systems.\",\n",
        "        \"Issues are product/device/software-specific.\",\n",
        "        \"Access, privacy, and timing are pain points.\",\n",
        "        \"Customers often describe steps taken or anomalies observed.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create the DataFrame\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Display the table\n",
        "summary_df\n"
      ],
      "metadata": {
        "id": "nfAU_eqS_8en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to CSV\n",
        "summary_df.to_csv(\"customer_support_summary.csv\", index=False)\n",
        "\n",
        "# Download the file (for Google Colab)\n",
        "from google.colab import files\n",
        "files.download(\"customer_support_summary.csv\")\n"
      ],
      "metadata": {
        "id": "H8uLvt43AR8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **âœ… Conclusion / Insights**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The analysis of customer support tickets revealed several important patterns:\n",
        "\n",
        "- **Recurring Issues**: Keywords such as *issue*, *problem*, *unable*, and *resolve* appeared frequently, indicating a high volume of functional and technical difficulties faced by users.\n",
        "- **Help Requests**: Words like *please*, *assist*, and *update* suggest that customers are actively seeking support and expect timely resolution.\n",
        "- **Product-Specific Concerns**: Terms like *product*, *device*, and *software* point to issues that are often tied to specific tools or technologies.\n",
        "- **Access and Data Problems**: Mentions of *account*, *data*, and *time* highlight common concerns related to login, privacy, and service delays.\n",
        "\n",
        "Additionally, a significant number of tickets lacked timely first responses and resolution times, pointing to inefficiencies in the current support workflow.  \n",
        "\n",
        "**Recommendation**:  \n",
        "To improve customer satisfaction and streamline resolution processes, organizations should consider:\n",
        "- Automating common responses using chatbots or knowledge bases.\n",
        "- Prioritizing ticket types based on keyword trends.\n",
        "- Enhancing support documentation to empower self-service.\n",
        "\n",
        "By leveraging data-driven insights, support teams can not only reduce resolution time but also build stronger relationships with customers through more effective and empathetic service.\n"
      ],
      "metadata": {
        "id": "sSxNj5fjBtZD"
      }
    }
  ]
}